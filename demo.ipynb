{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manitejaladi/real-time-animation/blob/master/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "<a href=\"https://kaggle.com/kernels/welcome?src=https://github.com/manitejaladi/real-time-animation/blob/master/demo.ipynb\" target=\"_parent\"><img alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdO_RxQZLahB"
      },
      "source": [
        "# Demo for paper \"Real Time Animation Model for Image Animation\"\n",
        "To try the demo, press the 2 play buttons in order and scroll to the bottom. Note that it may take several minutes to load."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCMFMJV7K-ag"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install ffmpeg-python imageio-ffmpeg\n",
        "!git init .\n",
        "!git remote add origin https://github.com/manitejaladi/rta\n",
        "!git pull origin master\n",
        "!git clone https://github.com/graphemecluster/first-order-model-demo demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oxi6-riLOgnm"
      },
      "outputs": [],
      "source": [
        "import IPython.display\n",
        "import PIL.Image\n",
        "import datetime\n",
        "import threading\n",
        "import cv2\n",
        "import time\n",
        "import ffmpeg\n",
        "import imageio\n",
        "import io\n",
        "import ipywidgets\n",
        "import numpy\n",
        "import os.path\n",
        "import requests\n",
        "import skimage.transform\n",
        "import warnings\n",
        "from base64 import b64encode\n",
        "from demo import load_checkpoints, make_animation  # type: ignore (local file)\n",
        "from google.colab import files, output\n",
        "from IPython.display import HTML, Javascript\n",
        "from shutil import copyfileobj\n",
        "from skimage import img_as_ubyte\n",
        "from tempfile import NamedTemporaryFile\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "import base64\n",
        "import io\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "import cv2\n",
        "import skimage\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.makedirs(\"user\", exist_ok=True)\n",
        "\n",
        "display(HTML(\"\"\"\n",
        "<style>\n",
        ".widget-box > * {\n",
        "\tflex-shrink: 0;\n",
        "}\n",
        ".widget-tab {\n",
        "\tmin-width: 0;\n",
        "\tflex: 1 1 auto;\n",
        "}\n",
        ".widget-tab .p-TabBar-tabLabel {\n",
        "\tfont-size: 15px;\n",
        "}\n",
        ".widget-upload {\n",
        "\tbackground-color: tan;\n",
        "}\n",
        ".widget-button {\n",
        "\tfont-size: 18px;\n",
        "\twidth: 160px;\n",
        "\theight: 34px;\n",
        "\tline-height: 34px;\n",
        "}\n",
        ".widget-dropdown {\n",
        "\twidth: 250px;\n",
        "}\n",
        ".widget-checkbox {\n",
        "\twidth: 650px;\n",
        "}\n",
        ".widget-checkbox + .widget-checkbox {\n",
        "\tmargin-top: -6px;\n",
        "}\n",
        ".input-widget .output_html {\n",
        "\ttext-align: center;\n",
        "\twidth: 266px;\n",
        "\theight: 266px;\n",
        "\tline-height: 266px;\n",
        "\tcolor: lightgray;\n",
        "\tfont-size: 72px;\n",
        "}\n",
        ".title {\n",
        "\tfont-size: 20px;\n",
        "\tfont-weight: bold;\n",
        "\tmargin: 12px 0 6px 0;\n",
        "}\n",
        ".warning {\n",
        "\tdisplay: none;\n",
        "\tcolor: red;\n",
        "\tmargin-left: 10px;\n",
        "}\n",
        ".warn {\n",
        "\tdisplay: initial;\n",
        "}\n",
        ".resource {\n",
        "\tcursor: pointer;\n",
        "\tborder: 1px solid gray;\n",
        "\tmargin: 5px;\n",
        "\twidth: 160px;\n",
        "\theight: 160px;\n",
        "\tmin-width: 160px;\n",
        "\tmin-height: 160px;\n",
        "\tmax-width: 160px;\n",
        "\tmax-height: 160px;\n",
        "\t-webkit-box-sizing: initial;\n",
        "\tbox-sizing: initial;\n",
        "}\n",
        ".resource:hover {\n",
        "\tborder: 6px solid crimson;\n",
        "\tmargin: 0;\n",
        "}\n",
        ".selected {\n",
        "\tborder: 6px solid seagreen;\n",
        "\tmargin: 0;\n",
        "}\n",
        ".input-widget {\n",
        "\twidth: 266px;\n",
        "\theight: 266px;\n",
        "\tborder: 1px solid gray;\n",
        "}\n",
        ".input-button {\n",
        "\twidth: 268px;\n",
        "\tfont-size: 15px;\n",
        "\tmargin: 2px 0 0;\n",
        "}\n",
        ".output-widget {\n",
        "\twidth: 256px;\n",
        "\theight: 256px;\n",
        "\tborder: 1px solid gray;\n",
        "}\n",
        ".output-button {\n",
        "\twidth: 258px;\n",
        "\tfont-size: 15px;\n",
        "\tmargin: 2px 0 0;\n",
        "}\n",
        ".uploaded {\n",
        "\twidth: 256px;\n",
        "\theight: 256px;\n",
        "\tborder: 6px solid seagreen;\n",
        "\tmargin: 0;\n",
        "}\n",
        ".label-or {\n",
        "\talign-self: center;\n",
        "\tfont-size: 20px;\n",
        "\tmargin: 16px;\n",
        "}\n",
        ".loading {\n",
        "\talign-items: center;\n",
        "\twidth: fit-content;\n",
        "}\n",
        ".loader {\n",
        "\tmargin: 32px 0 16px 0;\n",
        "\twidth: 48px;\n",
        "\theight: 48px;\n",
        "\tmin-width: 48px;\n",
        "\tmin-height: 48px;\n",
        "\tmax-width: 48px;\n",
        "\tmax-height: 48px;\n",
        "\tborder: 4px solid whitesmoke;\n",
        "\tborder-top-color: gray;\n",
        "\tborder-radius: 50%;\n",
        "\tanimation: spin 1.8s linear infinite;\n",
        "}\n",
        ".loading-label {\n",
        "\tcolor: gray;\n",
        "}\n",
        ".video {\n",
        "\tmargin: 0;\n",
        "}\n",
        ".comparison-widget {\n",
        "\twidth: 256px;\n",
        "\theight: 256px;\n",
        "\tborder: 1px solid gray;\n",
        "\tmargin-left: 2px;\n",
        "}\n",
        ".comparison-label {\n",
        "\tcolor: gray;\n",
        "\tfont-size: 14px;\n",
        "\ttext-align: center;\n",
        "\tposition: relative;\n",
        "\tbottom: 3px;\n",
        "}\n",
        "@keyframes spin {\n",
        "\tfrom { transform: rotate(0deg); }\n",
        "\tto { transform: rotate(360deg); }\n",
        "}\n",
        "</style>\n",
        "\"\"\"))\n",
        "\n",
        "def thumbnail(file):\n",
        "\treturn imageio.get_reader(file, mode='I', format='FFMPEG').get_next_data()\n",
        "\n",
        "def create_image(i, j):\n",
        "\timage_widget = ipywidgets.Image.from_file('demo/images/%d%d.png' % (i, j))\n",
        "\timage_widget.add_class('resource')\n",
        "\timage_widget.add_class('resource-image')\n",
        "\timage_widget.add_class('resource-image%d%d' % (i, j))\n",
        "\treturn image_widget\n",
        "\n",
        "def create_video(i):\n",
        "\tvideo_widget = ipywidgets.Image(\n",
        "\t\tvalue=cv2.imencode('.png', cv2.cvtColor(thumbnail('demo/videos/%d.mp4' % i), cv2.COLOR_RGB2BGR))[1].tostring(),\n",
        "\t\tformat='png'\n",
        "\t)\n",
        "\tvideo_widget.add_class('resource')\n",
        "\tvideo_widget.add_class('resource-video')\n",
        "\tvideo_widget.add_class('resource-video%d' % i)\n",
        "\treturn video_widget\n",
        "\n",
        "def create_title(title):\n",
        "\ttitle_widget = ipywidgets.Label(title)\n",
        "\ttitle_widget.add_class('title')\n",
        "\treturn title_widget\n",
        "\n",
        "def download_output(button):\n",
        "\tcomplete.layout.display = 'none'\n",
        "\tloading.layout.display = ''\n",
        "\tfiles.download('output.mp4')\n",
        "\tloading.layout.display = 'none'\n",
        "\tcomplete.layout.display = ''\n",
        "\n",
        "def convert_output(button):\n",
        "\tcomplete.layout.display = 'none'\n",
        "\tloading.layout.display = ''\n",
        "\tffmpeg.input('output.mp4').output('scaled.mp4', vf='scale=1080x1080:flags=lanczos,pad=1920:1080:420:0').overwrite_output().run()\n",
        "\tfiles.download('scaled.mp4')\n",
        "\tloading.layout.display = 'none'\n",
        "\tcomplete.layout.display = ''\n",
        "\n",
        "def back_to_main(button):\n",
        "\tcomplete.layout.display = 'none'\n",
        "\tmain.layout.display = ''\n",
        "\n",
        "\n",
        "# Commenting out the function call to prevent execution during optimization\n",
        "# upload_webcam_video(button=None)\n",
        "\n",
        "def record_video(filename='webcam_video.mp4', duration=5):\n",
        "    js = Javascript(\"\"\"\n",
        "    async function recordVideo(duration) {\n",
        "        // Create a video element to stream the webcam\n",
        "        const video = document.createElement('video');\n",
        "        video.style.display = 'block';\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "        // Append it to body to start the stream\n",
        "        document.body.appendChild(video);\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        // Create a canvas to capture a frame\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "        // Record a video\n",
        "        const recorder = new MediaRecorder(stream);\n",
        "        const data = [];\n",
        "        recorder.ondataavailable = event => data.push(event.data);\n",
        "        recorder.start();\n",
        "\n",
        "        // Stop the recording after the specified duration\n",
        "        const sleep = ms => new Promise(resolve => setTimeout(resolve, ms));\n",
        "        await sleep(duration * 1000);\n",
        "        recorder.stop();\n",
        "\n",
        "        // Wait for the recording to be finalized\n",
        "        await new Promise(resolve => recorder.onstop = resolve);\n",
        "\n",
        "        // Convert the recorded data chunks into a Blob\n",
        "        const blob = new Blob(data, { type: 'video/mp4' });\n",
        "        const url = URL.createObjectURL(blob);\n",
        "\n",
        "        // Read the Blob as a string to pass to Python\n",
        "        const reader = new FileReader();\n",
        "        reader.readAsDataURL(blob);\n",
        "        await new Promise(resolve => reader.onloadend = resolve);\n",
        "\n",
        "        // Remove the video element and return the data URL\n",
        "        video.remove();\n",
        "        return reader.result;\n",
        "    }\n",
        "    \"\"\")\n",
        "    display(js)\n",
        "    video_data_url = eval_js('recordVideo({})'.format(duration))\n",
        "    video_binary = b64decode(video_data_url.split(',')[1])\n",
        "\n",
        "    # Save the video to a file\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(video_binary)\n",
        "\n",
        "    # Use ffmpeg to convert the video to the desired resolution\n",
        "    output_filename = f'processed_{filename}'\n",
        "    cmd = (\n",
        "        ffmpeg\n",
        "        .input(filename)\n",
        "        .output(output_filename, vf='scale=256:256')  # Set your desired resolution here\n",
        "        .overwrite_output()\n",
        "        .run_async(pipe_stdout=True, pipe_stderr=True)\n",
        "    )\n",
        "    out, err = cmd.communicate()\n",
        "    if cmd.returncode == 0:\n",
        "        os.rename(output_filename, filename)  # Replace the original file with the resized version\n",
        "    else:\n",
        "        print(f\"ffmpeg error: {err.decode('utf8')}\")\n",
        "\n",
        "    return filename\n",
        "\n",
        "# Now, use the function to record a video\n",
        "recorded_video_filename = 'webcam_video.mp4'\n",
        "record_video(recorded_video_filename, duration=10)\n",
        "\n",
        "def create_video_tab_content():\n",
        "    # Load thumbnails for all demo videos plus the recorded video\n",
        "    video_widgets = []\n",
        "    # Add the recorded video thumbnail first\n",
        "    if os.path.isfile(recorded_video_filename):\n",
        "        video_widget = ipywidgets.Image(\n",
        "            value=cv2.imencode('.png', cv2.cvtColor(thumbnail(recorded_video_filename), cv2.COLOR_RGB2BGR))[1].tostring(),\n",
        "            format='png',\n",
        "            width=160,\n",
        "            height=160\n",
        "        )\n",
        "        video_widget.add_class('resource-video')\n",
        "        video_widget.add_class('resource-video0')  # Use '0' for the recorded video\n",
        "        video_widgets.append(video_widget)\n",
        "\n",
        "    # Add thumbnails for demo videos\n",
        "    for i in range(5):  # Assuming you have 5 demo videos\n",
        "        video_widget = ipywidgets.Image(\n",
        "            value=cv2.imencode('.png', cv2.cvtColor(thumbnail(f'demo/videos/{i}.mp4'), cv2.COLOR_RGB2BGR))[1].tostring(),\n",
        "            format='png',\n",
        "            width=160,\n",
        "            height=160\n",
        "        )\n",
        "        video_widget.add_class('resource-video')\n",
        "        video_widget.add_class(f'resource-video{i+1}')  # Increment the index by 1\n",
        "        video_widgets.append(video_widget)\n",
        "    return video_widgets\n",
        "\n",
        "\n",
        "label_or = ipywidgets.Label('or')\n",
        "label_or.add_class('label-or')\n",
        "\n",
        "image_titles = ['Peoples', 'Cartoons', 'Dolls', 'Game of Thrones', 'Statues']\n",
        "image_lengths = [8, 4, 8, 9, 4]\n",
        "\n",
        "image_tab = ipywidgets.Tab()\n",
        "image_tab.children = [ipywidgets.HBox([create_image(i, j) for j in range(length)]) for i, length in enumerate(image_lengths)]\n",
        "for i, title in enumerate(image_titles):\n",
        "\timage_tab.set_title(i, title)\n",
        "\n",
        "input_image_widget = ipywidgets.Output()\n",
        "input_image_widget.add_class('input-widget')\n",
        "upload_input_image_button = ipywidgets.FileUpload(accept='image/*', button_style='primary')\n",
        "upload_input_image_button.add_class('input-button')\n",
        "image_part = ipywidgets.HBox([\n",
        "\tipywidgets.VBox([input_image_widget, upload_input_image_button]),\n",
        "\tlabel_or,\n",
        "\timage_tab\n",
        "])\n",
        "\n",
        "video_tab = ipywidgets.Tab()\n",
        "video_tab.children = [ipywidgets.HBox(create_video_tab_content())]\n",
        "for i, widget in enumerate(video_tab.children[0].children):\n",
        "    video_tab.set_title(i, f'Video {i}')  # Set titles for the tabs\n",
        "\n",
        "input_video_widget = ipywidgets.Output()\n",
        "input_video_widget.add_class('input-widget')\n",
        "upload_input_video_button = ipywidgets.FileUpload(accept='video/*', button_style='primary')\n",
        "upload_input_video_button.add_class('input-button')\n",
        "video_part = ipywidgets.HBox([\n",
        "    ipywidgets.VBox([input_video_widget, upload_input_video_button]),  # Add record button here\n",
        "    label_or,\n",
        "    video_tab\n",
        "])\n",
        "\n",
        "\n",
        "# # Now, let's integrate the recording functionality with the UI interaction\n",
        "# record_video_button = ipywidgets.Button(description='Record Video')\n",
        "# record_video_button.on_click(upload_webcam_video)\n",
        "\n",
        "\n",
        "model = ipywidgets.Dropdown(\n",
        "\tdescription=\"Model:\",\n",
        "\toptions=[\n",
        "\t\t'vox',\n",
        "\t\t'vox-adv',\n",
        "\t\t'taichi',\n",
        "\t\t'taichi-adv',\n",
        "\t\t'nemo',\n",
        "\t\t'mgif',\n",
        "\t\t'fashion',\n",
        "\t\t'bair'\n",
        "\t]\n",
        ")\n",
        "warning = ipywidgets.HTML('<b>Warning:</b> Upload your own images and videos (see README)')\n",
        "warning.add_class('warning')\n",
        "model_part = ipywidgets.HBox([model, warning])\n",
        "\n",
        "relative = ipywidgets.Checkbox(description=\"Relative keypoint displacement (Inherit object proporions from the video)\", value=True)\n",
        "adapt_movement_scale = ipywidgets.Checkbox(description=\"Adapt movement scale (Don’t touch unless you know want you are doing)\", value=True)\n",
        "generate_button = ipywidgets.Button(description=\"Generate\", button_style='primary')\n",
        "main = ipywidgets.VBox([\n",
        "\tcreate_title('Choose Image'),\n",
        "\timage_part,\n",
        "\tcreate_title('Choose Video'),\n",
        "\tvideo_part,\n",
        "\tcreate_title('Settings'),\n",
        "\tmodel_part,\n",
        "\trelative,\n",
        "\tadapt_movement_scale,\n",
        "\tgenerate_button\n",
        "])\n",
        "\n",
        "loader = ipywidgets.Label()\n",
        "loader.add_class(\"loader\")\n",
        "loading_label = ipywidgets.Label(\"This may take several minutes to process…\")\n",
        "loading_label.add_class(\"loading-label\")\n",
        "progress_bar = ipywidgets.Output()\n",
        "loading = ipywidgets.VBox([loader, loading_label, progress_bar])\n",
        "loading.add_class('loading')\n",
        "\n",
        "output_widget = ipywidgets.Output()\n",
        "output_widget.add_class('output-widget')\n",
        "download = ipywidgets.Button(description='Download', button_style='primary')\n",
        "download.add_class('output-button')\n",
        "download.on_click(download_output)\n",
        "convert = ipywidgets.Button(description='Convert to 1920×1080', button_style='primary')\n",
        "convert.add_class('output-button')\n",
        "convert.on_click(convert_output)\n",
        "back = ipywidgets.Button(description='Back', button_style='primary')\n",
        "back.add_class('output-button')\n",
        "back.on_click(back_to_main)\n",
        "\n",
        "comparison_widget = ipywidgets.Output()\n",
        "comparison_widget.add_class('comparison-widget')\n",
        "comparison_label = ipywidgets.Label('Comparison')\n",
        "comparison_label.add_class('comparison-label')\n",
        "complete = ipywidgets.HBox([\n",
        "\tipywidgets.VBox([output_widget, download, convert, back]),\n",
        "\tipywidgets.VBox([comparison_widget, comparison_label])\n",
        "])\n",
        "\n",
        "display(ipywidgets.VBox([main, loading, complete]))\n",
        "display(Javascript(\"\"\"\n",
        "var images, videos;\n",
        "function deselectImages() {\n",
        "\timages.forEach(function(item) {\n",
        "\t\titem.classList.remove(\"selected\");\n",
        "\t});\n",
        "}\n",
        "function deselectVideos() {\n",
        "\tvideos.forEach(function(item) {\n",
        "\t\titem.classList.remove(\"selected\");\n",
        "\t});\n",
        "}\n",
        "function invokePython(func) {\n",
        "\tgoogle.colab.kernel.invokeFunction(\"notebook.\" + func, [].slice.call(arguments, 1), {});\n",
        "}\n",
        "setTimeout(function() {\n",
        "\t(images = [].slice.call(document.getElementsByClassName(\"resource-image\"))).forEach(function(item) {\n",
        "\t\titem.addEventListener(\"click\", function() {\n",
        "\t\t\tdeselectImages();\n",
        "\t\t\titem.classList.add(\"selected\");\n",
        "\t\t\tinvokePython(\"select_image\", item.className.match(/resource-image(\\d\\d)/)[1]);\n",
        "\t\t});\n",
        "\t});\n",
        "\timages[0].classList.add(\"selected\");\n",
        "\t(videos = [].slice.call(document.getElementsByClassName(\"resource-video\"))).forEach(function(item) {\n",
        "\t\titem.addEventListener(\"click\", function() {\n",
        "\t\t\tdeselectVideos();\n",
        "\t\t\titem.classList.add(\"selected\");\n",
        "\t\t\tinvokePython(\"select_video\", item.className.match(/resource-video(\\d)/)[1]);\n",
        "\t\t});\n",
        "\t});\n",
        "\tvideos[0].classList.add(\"selected\");\n",
        "}, 1000);\n",
        "\"\"\"))\n",
        "\n",
        "selected_image = None\n",
        "def select_image(filename):\n",
        "\tglobal selected_image\n",
        "\tselected_image = resize(PIL.Image.open('demo/images/%s.png' % filename).convert(\"RGB\"))\n",
        "\tinput_image_widget.clear_output(wait=True)\n",
        "\twith input_image_widget:\n",
        "\t\tdisplay(HTML('Image'))\n",
        "\tinput_image_widget.remove_class('uploaded')\n",
        "output.register_callback(\"notebook.select_image\", select_image)\n",
        "\n",
        "selected_video = None\n",
        "def select_video(index):\n",
        "    global selected_video\n",
        "    if index == '0':\n",
        "        selected_video = recorded_video_filename\n",
        "    else:\n",
        "        selected_video = f'demo/videos/{index}.mp4'\n",
        "    input_video_widget.clear_output(wait=True)\n",
        "    with input_video_widget:\n",
        "        if os.path.exists(selected_video):\n",
        "            display(ipywidgets.Video.from_file(selected_video, width=256, height=256))\n",
        "        else:\n",
        "            print(\"Video file not found: \", selected_video)\n",
        "\n",
        "# Register the select_video callback\n",
        "output.register_callback(\"notebook.select_video\", select_video)\n",
        "\n",
        "def resize(image, size=(256, 256)):\n",
        "\tw, h = image.size\n",
        "\td = min(w, h)\n",
        "\tr = ((w - d) // 2, (h - d) // 2, (w + d) // 2, (h + d) // 2)\n",
        "\treturn image.resize(size, resample=PIL.Image.LANCZOS, box=r)\n",
        "\n",
        "def upload_image(change):\n",
        "\tglobal selected_image\n",
        "\tfor name, file_info in upload_input_image_button.value.items():\n",
        "\t\tcontent = file_info['content']\n",
        "\tif content is not None:\n",
        "\t\tselected_image = resize(PIL.Image.open(io.BytesIO(content)).convert(\"RGB\"))\n",
        "\t\tinput_image_widget.clear_output(wait=True)\n",
        "\t\twith input_image_widget:\n",
        "\t\t\tdisplay(selected_image)\n",
        "\t\tinput_image_widget.add_class('uploaded')\n",
        "\t\tdisplay(Javascript('deselectImages()'))\n",
        "upload_input_image_button.observe(upload_image, names='value')\n",
        "\n",
        "def upload_video(change):\n",
        "\tglobal selected_video\n",
        "\tfor name, file_info in upload_input_video_button.value.items():\n",
        "\t\tcontent = file_info['content']\n",
        "\tif content is not None:\n",
        "\t\tselected_video = 'user/' + name\n",
        "\t\twith open(selected_video, 'wb') as video:\n",
        "\t\t\tvideo.write(content)\n",
        "\t\tpreview = resize(PIL.Image.fromarray(thumbnail(selected_video)).convert(\"RGB\"))\n",
        "\t\tinput_video_widget.clear_output(wait=True)\n",
        "\t\twith input_video_widget:\n",
        "\t\t\tdisplay(preview)\n",
        "\t\tinput_video_widget.add_class('uploaded')\n",
        "\t\tdisplay(Javascript('deselectVideos()'))\n",
        "upload_input_video_button.observe(upload_video, names='value')\n",
        "\n",
        "def change_model(change):\n",
        "\tif model.value.startswith('vox'):\n",
        "\t\twarning.remove_class('warn')\n",
        "\telse:\n",
        "\t\twarning.add_class('warn')\n",
        "model.observe(change_model, names='value')\n",
        "\n",
        "def calculate_l1_error(original, generated):\n",
        "    # Assuming original and generated are numpy arrays of the same shape\n",
        "    return np.mean(np.abs(original - generated))\n",
        "\n",
        "def calculate_aed(original, generated):\n",
        "    # Flatten the frames to calculate the Euclidean distance across corresponding pixels\n",
        "    return np.mean(np.linalg.norm(original.reshape(-1, 3) - generated.reshape(-1, 3), axis=1))\n",
        "\n",
        "# Assuming keypoints are extracted or available\n",
        "def calculate_akd(original_keypoints, generated_keypoints):\n",
        "    return np.mean(np.linalg.norm(original_keypoints - generated_keypoints, axis=1))\n",
        "\n",
        "def calculate_mkr(original_keypoints, generated_keypoints, threshold=0.01):\n",
        "    distances = np.linalg.norm(original_keypoints - generated_keypoints, axis=1)\n",
        "    missing_count = np.sum(distances > threshold)\n",
        "    total_keypoints = len(original_keypoints)\n",
        "    return missing_count / total_keypoints\n",
        "\n",
        "# Function to compare two videos and calculate metrics\n",
        "def compare_videos(original_video_path, generated_video_path):\n",
        "    original_cap = cv2.VideoCapture(original_video_path)\n",
        "    generated_cap = cv2.VideoCapture(generated_video_path)\n",
        "\n",
        "    l1_errors, aeds = [], []\n",
        "    while True:\n",
        "        ret_orig, frame_orig = original_cap.read()\n",
        "        ret_gen, frame_gen = generated_cap.read()\n",
        "\n",
        "        if not ret_orig or not ret_gen:\n",
        "            break\n",
        "\n",
        "        # Resize for comparison if necessary\n",
        "        frame_gen = cv2.resize(frame_gen, (frame_orig.shape[1], frame_orig.shape[0]))\n",
        "\n",
        "        # Calculate metrics\n",
        "        l1_error = calculate_l1_error(frame_orig, frame_gen)\n",
        "        aed = calculate_aed(frame_orig, frame_gen)\n",
        "\n",
        "        l1_errors.append(l1_error)\n",
        "        aeds.append(aed)\n",
        "\n",
        "    original_cap.release()\n",
        "    generated_cap.release()\n",
        "\n",
        "    # Average the errors over all frames\n",
        "    average_l1_error = np.mean(l1_errors)\n",
        "    average_aed = np.mean(aeds)\n",
        "\n",
        "    print(f\"Average L1 Error: {average_l1_error}\")\n",
        "    print(f\"Average AED: {average_aed}\")\n",
        "\n",
        "def generate(button):\n",
        "    main.layout.display = 'none'\n",
        "    loading.layout.display = ''\n",
        "    filename = model.value + ('' if model.value == 'fashion' else '-cpk') + '.pth.tar'\n",
        "    if not os.path.isfile(filename):\n",
        "        response = requests.get('https://github.com/graphemecluster/first-order-model-demo/releases/download/checkpoints/' + filename, stream=True)\n",
        "        with progress_bar:\n",
        "            with tqdm.wrapattr(response.raw, 'read', total=int(response.headers.get('Content-Length', 0)), unit='B', unit_scale=True, unit_divisor=1024) as raw:\n",
        "                with open(filename, 'wb') as file:\n",
        "                    copyfileobj(raw, file)\n",
        "        progress_bar.clear_output()\n",
        "    reader = imageio.get_reader(selected_video, mode='I', format='FFMPEG')\n",
        "    fps = reader.get_meta_data()['fps']\n",
        "    driving_video = []\n",
        "    for frame in reader:\n",
        "        driving_video.append(frame)\n",
        "    generator, kp_detector = load_checkpoints(config_path='config/%s-256.yaml' % model.value, checkpoint_path=filename)\n",
        "    with progress_bar:\n",
        "        predictions = make_animation(\n",
        "            skimage.transform.resize(numpy.asarray(selected_image), (256, 256)),\n",
        "            [skimage.transform.resize(frame, (256, 256)) for frame in driving_video],\n",
        "            generator,\n",
        "            kp_detector,\n",
        "            relative=relative.value,\n",
        "            adapt_movement_scale=adapt_movement_scale.value\n",
        "        )\n",
        "    progress_bar.clear_output()\n",
        "    imageio.mimsave('output.mp4', [img_as_ubyte(frame) for frame in predictions], fps=fps)\n",
        "    try:\n",
        "        with NamedTemporaryFile(suffix='.mp4') as output:\n",
        "            ffmpeg.output(ffmpeg.input('output.mp4').video, ffmpeg.input(selected_video).audio, output.name, c='copy').run()\n",
        "            with open('output.mp4', 'wb') as result:\n",
        "                copyfileobj(output, result)\n",
        "    except ffmpeg.Error:\n",
        "        pass\n",
        "    output_widget.clear_output(True)\n",
        "    with output_widget:\n",
        "        video_widget = ipywidgets.Video.from_file('output.mp4', autoplay=False, loop=False)\n",
        "        video_widget.add_class('video')\n",
        "        video_widget.add_class('video-left')\n",
        "        display(video_widget)\n",
        "    comparison_widget.clear_output(True)\n",
        "    with comparison_widget:\n",
        "        video_widget = ipywidgets.Video.from_file(selected_video, autoplay=False, loop=False, controls=False)\n",
        "        video_widget.add_class('video')\n",
        "        video_widget.add_class('video-right')\n",
        "        display(video_widget)\n",
        "    display(Javascript(\"\"\"\n",
        "    setTimeout(function() {\n",
        "        (function(left, right) {\n",
        "            left.addEventListener(\"play\", function() {\n",
        "                right.play();\n",
        "            });\n",
        "            left.addEventListener(\"pause\", function() {\n",
        "                right.pause();\n",
        "            });\n",
        "            left.addEventListener(\"seeking\", function() {\n",
        "                right.currentTime = left.currentTime;\n",
        "            });\n",
        "            right.muted = true;\n",
        "        })(document.getElementsByClassName(\"video-left\")[0], document.getElementsByClassName(\"video-right\")[0]);\n",
        "    }, 1000);\n",
        "    \"\"\"))\n",
        "    loading.layout.display = 'none'\n",
        "    complete.layout.display = ''\n",
        "\n",
        "    # Assume selected_video contains the path to the original video\n",
        "    original_video_path = selected_video  # directly using selected_video as the original path\n",
        "    generated_video_path = 'output.mp4'  # output.mp4 is already defined above\n",
        "\n",
        "    # Call the function to compare the videos\n",
        "    compare_videos(original_video_path, generated_video_path)\n",
        "\n",
        "\n",
        "generate_button.on_click(generate)\n",
        "\n",
        "loading.layout.display = 'none'\n",
        "complete.layout.display = 'none'\n",
        "select_image('00')\n",
        "select_video('0')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "real-time-animation",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
